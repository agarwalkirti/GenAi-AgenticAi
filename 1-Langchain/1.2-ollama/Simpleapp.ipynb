{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3085f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## simple genai app using langchain and ollama model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b60f56c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current LangSmith project: GenAIAPPwithOllama\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables first\n",
    "load_dotenv()\n",
    "\n",
    "# Set LangSmith configuration variables before importing any LangChain components\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "os.environ[\"SIMPLE_LANGCHAIN_PROJECT\"] = os.getenv(\"SIMPLE_LANGCHAIN_PROJECT\")\n",
    "\n",
    "# Verify LangSmith project is set\n",
    "print(\"Current LangSmith project:\", os.getenv(\"SIMPLE_LANGCHAIN_PROJECT\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5914a09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beautiful soup is a traditional American dish consisting of noodles and vegetables. It is a light and flavorful soup that is often served with butter or cream. The noodles in beautiful soup can be made from a variety of ingredients, such as wheat, barley, or potato. The vegetables in beautiful soup can include celery, carrots, onions, and potatoes.\n"
     ]
    }
   ],
   "source": [
    "from langsmith.run_helpers import traceable\n",
    "from langchain_ollama import ChatOllama #as openai is paid\n",
    "\n",
    "llm = ChatOllama(model=\"gemma:2b\")  # or llama2, mistral, etc.\n",
    "# Wrap your function so LangSmith logs it\n",
    "@traceable(name=\"ollama-query-wrapped\", project_name=os.getenv(\"SIMPLE_LANGCHAIN_PROJECT\"))\n",
    "def ask_ollama(q: str):\n",
    "    return llm.invoke(q).content\n",
    "\n",
    "# Run a query\n",
    "print(ask_ollama(\"What is beautiful soup?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "395e984b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying LangSmith Project Configuration:\n",
      "Current Project: GenAIAPPwithOPENAI\n",
      "\n",
      "Available Projects:\n",
      "- GenAIAPPwithOllama\n",
      "- GenAIAPPwithOPENAI\n",
      "- default\n"
     ]
    }
   ],
   "source": [
    "# Verify LangSmith connection\n",
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "print(\"\\nVerifying LangSmith Project Configuration:\")\n",
    "print(f\"Current Project: {os.getenv('LANGCHAIN_PROJECT')}\")\n",
    "print(\"\\nAvailable Projects:\")\n",
    "for p in client.list_projects():\n",
    "    print(f\"- {p.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d42e652e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 documents from https://docs.langchain.com/langsmith/architectural-overview\n"
     ]
    }
   ],
   "source": [
    "#data injetion -> from website we need to scrape the data \n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "url = \"https://docs.langchain.com/langsmith/architectural-overview\"\n",
    "loader = WebBaseLoader(url)\n",
    "data = loader.load()\n",
    "print(f\"Loaded {len(data)} documents from {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "21fe9a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.langchain.com/langsmith/architectural-overview', 'title': 'Architectural overview - Docs by LangChain', 'language': 'en'}, page_content='Architectural overview - Docs by LangChainDocs by LangChain home pagePythonSearch...⌘KLangSmithPlatform for LLM observability and evaluationOverviewSetupInstall on KubernetesInstall on DockerInteract with an installationUpgrade an installationConfigure egress for subscription metricsView trace counts across an organizationLangSmith-managed ClickHouseConfigurationConfigure for scaleEnable TTL & data retentionCreate an Ingress for installations (Kubernetes)Mirror images for your installationUse environment variables for model providersTroubleshootingAuthentication & access controlSet up basic authenticationSet up SSO with OAuth2.0 & OIDCCustomize user managementConfigure custom TLS certificatesUse an existing secret for your installation (Kubernetes)Connect external servicesEnable blob storageConnect to an external ClickHouse databaseConnect to an external PostgreSQL databaseConnect to an external Redis databaseScriptsDelete workspacesDelete organizationsDelete tracesGenerate ClickHouse StatsGenerate query statsRun support queries against PostgreSQLRun support queries against ClickHouseObservabilityExport LangSmith telemetry to your observability backendConfigure your collector for telemetryDeploy an observability stackDocs by LangChain home pagePythonSearch...⌘KGitHubForumForumSearch...NavigationArchitectural overviewGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGitHubForumOn this pageStorage ServicesClickHousePostgreSQLRedisBlob storageServicesLangSmith frontendLangSmith backendLangSmith queueLangSmith platform backendLangSmith PlaygroundLangSmith ACE (Arbitrary Code Execution) backendArchitectural overviewCopy pageCopy pageSelf-hosted LangSmith is an add-on to the Enterprise Plan designed for our largest, most security-conscious customers. See our pricing page for more detail, and contact our sales team if you want to get a license key to trial LangSmith in your environment.\\nYou can run LangSmith in Kubernetes (recommended) or Docker in a cloud environment that you control. The LangSmith application consists of several components including LangSmith servers and stateful services:\\n\\nLangSmith frontend\\nLangSmith backend\\nLangSmith platform backend\\nLangSmith Playground\\nLangSmith queue\\nLangSmith ACE (Arbitrary Code Execution) backend\\nClickHouse\\nPostgreSQL\\nRedis\\nBlob storage (Optional, but recommended)\\n\\n\\nTo access the LangSmith UI and send API requests, you will need to expose the LangSmith frontend service. Depending on your installation method, this can be a load balancer or a port exposed on the host machine.\\n\\u200bStorage Services\\nLangSmith Self-Hosted will bundle all storage services by default. You can configure LangSmith to use external versions of all storage services. In a production setting, we strongly recommend using external storage services.\\n\\u200bClickHouse\\nClickHouse is a high-performance, column-oriented SQL database management system (DBMS) for online analytical processing (OLAP).\\nLangSmith uses ClickHouse as the primary data store for traces and feedback (high-volume data).\\n\\u200bPostgreSQL\\nPostgreSQL is a powerful, open source object-relational database system that uses and extends the SQL language combined with many features that safely store and scale the most complicated data workloads\\nLangSmith uses PostgreSQL as the primary data store for transactional workloads and operational data (almost everything besides traces and feedback).\\n\\u200bRedis\\nRedis is a powerful in-memory key-value database that persists on disk. By holding data in memory, Redis offers high performance for operations like caching.\\nLangSmith uses Redis to back queuing and caching operations.\\n\\u200bBlob storage\\nLangSmith supports several blob storage providers, including AWS S3, Azure Blob Storage, and Google Cloud Storage.\\nLangSmith uses blob storage to store large files, such as trace artifacts, feedback attachments, and other large data objects. Blob storage is optional, but highly recommended for production deployments.\\n\\u200bServices\\n\\u200bLangSmith frontend\\nThe frontend uses Nginx to serve the LangSmith UI and route API requests to the other servers. This serves as the entrypoint for the application and is the only component that must be exposed to users.\\n\\u200bLangSmith backend\\nThe backend is the main entrypoint for CRUD API requests and handles the majority of the business logic for the application. This includes handling requests from the frontend and SDK, preparing traces for ingestion, and supporting the hub API.\\n\\u200bLangSmith queue\\nThe queue handles incoming traces and feedback to ensure that they are ingested and persisted into the traces and feedback datastore asynchronously, handling checks for data integrity and ensuring successful insert into the datastore, handling retries in situations such as database errors or the temporary inability to connect to the database.\\n\\u200bLangSmith platform backend\\nThe platform backend is another critical service that primarily handles authentication, run ingestion, and other high-volume tasks.\\n\\u200bLangSmith Playground\\nThe playground is a service that handles forwarding requests to various LLM APIs to support the LangSmith Playground feature. This can also be used to connect to your own custom model servers.\\n\\u200bLangSmith ACE (Arbitrary Code Execution) backend\\nThe ACE backend is a service that handles executing arbitrary code in a secure environment. This is used to support running custom code within LangSmith.Was this page helpful?YesNoInstall on KubernetesAssistantResponses are generated using AI and may contain mistakes.Docs by LangChain home pagegithubxlinkedinyoutubeResourcesChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify')]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "20771de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splited into 9 chunks\n"
     ]
    }
   ],
   "source": [
    "# load data -->docs -->divide our text into  chunks -->vectors -->use vector embeddings--> store in a vector store db\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(data)\n",
    "print(f\"Splited into {len(documents)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c9b5b080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.langchain.com/langsmith/architectural-overview', 'title': 'Architectural overview - Docs by LangChain', 'language': 'en'}, page_content='Architectural overview - Docs by LangChainDocs by LangChain home pagePythonSearch...⌘KLangSmithPlatform for LLM observability and evaluationOverviewSetupInstall on KubernetesInstall on DockerInteract with an installationUpgrade an installationConfigure egress for subscription metricsView trace counts across an organizationLangSmith-managed ClickHouseConfigurationConfigure for scaleEnable TTL & data retentionCreate an Ingress for installations (Kubernetes)Mirror images for your installationUse environment variables for model providersTroubleshootingAuthentication & access controlSet up basic authenticationSet up SSO with OAuth2.0 & OIDCCustomize user managementConfigure custom TLS certificatesUse an existing secret for your installation (Kubernetes)Connect external servicesEnable blob storageConnect to an external ClickHouse databaseConnect to an external PostgreSQL databaseConnect to an external Redis databaseScriptsDelete workspacesDelete organizationsDelete tracesGenerate ClickHouse'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/architectural-overview', 'title': 'Architectural overview - Docs by LangChain', 'language': 'en'}, page_content='to an external ClickHouse databaseConnect to an external PostgreSQL databaseConnect to an external Redis databaseScriptsDelete workspacesDelete organizationsDelete tracesGenerate ClickHouse StatsGenerate query statsRun support queries against PostgreSQLRun support queries against ClickHouseObservabilityExport LangSmith telemetry to your observability backendConfigure your collector for telemetryDeploy an observability stackDocs by LangChain home pagePythonSearch...⌘KGitHubForumForumSearch...NavigationArchitectural overviewGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGitHubForumOn this pageStorage ServicesClickHousePostgreSQLRedisBlob storageServicesLangSmith frontendLangSmith backendLangSmith queueLangSmith platform backendLangSmith PlaygroundLangSmith ACE (Arbitrary Code Execution) backendArchitectural overviewCopy pageCopy pageSelf-hosted LangSmith is an add-on to the'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/architectural-overview', 'title': 'Architectural overview - Docs by LangChain', 'language': 'en'}, page_content='backendLangSmith queueLangSmith platform backendLangSmith PlaygroundLangSmith ACE (Arbitrary Code Execution) backendArchitectural overviewCopy pageCopy pageSelf-hosted LangSmith is an add-on to the Enterprise Plan designed for our largest, most security-conscious customers. See our pricing page for more detail, and contact our sales team if you want to get a license key to trial LangSmith in your environment.'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/architectural-overview', 'title': 'Architectural overview - Docs by LangChain', 'language': 'en'}, page_content='You can run LangSmith in Kubernetes (recommended) or Docker in a cloud environment that you control. The LangSmith application consists of several components including LangSmith servers and stateful services:'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/architectural-overview', 'title': 'Architectural overview - Docs by LangChain', 'language': 'en'}, page_content='LangSmith frontend\\nLangSmith backend\\nLangSmith platform backend\\nLangSmith Playground\\nLangSmith queue\\nLangSmith ACE (Arbitrary Code Execution) backend\\nClickHouse\\nPostgreSQL\\nRedis\\nBlob storage (Optional, but recommended)'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/architectural-overview', 'title': 'Architectural overview - Docs by LangChain', 'language': 'en'}, page_content='To access the LangSmith UI and send API requests, you will need to expose the LangSmith frontend service. Depending on your installation method, this can be a load balancer or a port exposed on the host machine.\\n\\u200bStorage Services\\nLangSmith Self-Hosted will bundle all storage services by default. You can configure LangSmith to use external versions of all storage services. In a production setting, we strongly recommend using external storage services.\\n\\u200bClickHouse\\nClickHouse is a high-performance, column-oriented SQL database management system (DBMS) for online analytical processing (OLAP).\\nLangSmith uses ClickHouse as the primary data store for traces and feedback (high-volume data).\\n\\u200bPostgreSQL\\nPostgreSQL is a powerful, open source object-relational database system that uses and extends the SQL language combined with many features that safely store and scale the most complicated data workloads'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/architectural-overview', 'title': 'Architectural overview - Docs by LangChain', 'language': 'en'}, page_content='LangSmith uses PostgreSQL as the primary data store for transactional workloads and operational data (almost everything besides traces and feedback).\\n\\u200bRedis\\nRedis is a powerful in-memory key-value database that persists on disk. By holding data in memory, Redis offers high performance for operations like caching.\\nLangSmith uses Redis to back queuing and caching operations.\\n\\u200bBlob storage\\nLangSmith supports several blob storage providers, including AWS S3, Azure Blob Storage, and Google Cloud Storage.\\nLangSmith uses blob storage to store large files, such as trace artifacts, feedback attachments, and other large data objects. Blob storage is optional, but highly recommended for production deployments.\\n\\u200bServices\\n\\u200bLangSmith frontend\\nThe frontend uses Nginx to serve the LangSmith UI and route API requests to the other servers. This serves as the entrypoint for the application and is the only component that must be exposed to users.\\n\\u200bLangSmith backend'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/architectural-overview', 'title': 'Architectural overview - Docs by LangChain', 'language': 'en'}, page_content='\\u200bLangSmith backend\\nThe backend is the main entrypoint for CRUD API requests and handles the majority of the business logic for the application. This includes handling requests from the frontend and SDK, preparing traces for ingestion, and supporting the hub API.\\n\\u200bLangSmith queue\\nThe queue handles incoming traces and feedback to ensure that they are ingested and persisted into the traces and feedback datastore asynchronously, handling checks for data integrity and ensuring successful insert into the datastore, handling retries in situations such as database errors or the temporary inability to connect to the database.\\n\\u200bLangSmith platform backend\\nThe platform backend is another critical service that primarily handles authentication, run ingestion, and other high-volume tasks.\\n\\u200bLangSmith Playground\\nThe playground is a service that handles forwarding requests to various LLM APIs to support the LangSmith Playground feature. This can also be used to connect to your own custom model servers.'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/architectural-overview', 'title': 'Architectural overview - Docs by LangChain', 'language': 'en'}, page_content='The playground is a service that handles forwarding requests to various LLM APIs to support the LangSmith Playground feature. This can also be used to connect to your own custom model servers.\\n\\u200bLangSmith ACE (Arbitrary Code Execution) backend\\nThe ACE backend is a service that handles executing arbitrary code in a secure environment. This is used to support running custom code within LangSmith.Was this page helpful?YesNoInstall on KubernetesAssistantResponses are generated using AI and may contain mistakes.Docs by LangChain home pagegithubxlinkedinyoutubeResourcesChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify')]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "397ab2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created vectorstore with 9 vectors\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "embeddings = OllamaEmbeddings(model=\"gemma:2b\")  # or llama\n",
    "vectorstoredb = FAISS.from_documents(documents, embeddings)\n",
    "print(f\"Created vectorstore with {vectorstoredb.index.ntotal} vectors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e56fe7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x22d7a6db460>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstoredb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "caec7ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 similar documents.\n"
     ]
    }
   ],
   "source": [
    "#query from vector store db\n",
    "query = \"Need to expose the LangSmith frontend\"\n",
    "result_docs = vectorstoredb.similarity_search(query, k=6)\n",
    "print(f\"Found {len(result_docs)} similar documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "15d802b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith uses PostgreSQL as the primary data store for transactional workloads and operational data (almost everything besides traces and feedback).\\n\\u200bRedis\\nRedis is a powerful in-memory key-value database that persists on disk. By holding data in memory, Redis offers high performance for operations like caching.\\nLangSmith uses Redis to back queuing and caching operations.\\n\\u200bBlob storage\\nLangSmith supports several blob storage providers, including AWS S3, Azure Blob Storage, and Google Cloud Storage.\\nLangSmith uses blob storage to store large files, such as trace artifacts, feedback attachments, and other large data objects. Blob storage is optional, but highly recommended for production deployments.\\n\\u200bServices\\n\\u200bLangSmith frontend\\nThe frontend uses Nginx to serve the LangSmith UI and route API requests to the other servers. This serves as the entrypoint for the application and is the only component that must be exposed to users.\\n\\u200bLangSmith backend'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c0f9e7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\n    Answer the following question based only on the provided context:\\n    <context>\\n      {context}\\n    </context>\\n\\n     '), additional_kwargs={})])\n",
       "| ChatOllama(model='gemma:2b')\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrieval chain and document chain\n",
    "# document chain --> how to combine the document and prompt together, it is responsible for giving me context information.\n",
    "# retrieval chain --> how to retrieve the relevant documents based on the query\n",
    "# llm --> the language model we are using to generate the answer\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the following question based only on the provided context:\n",
    "    <context>\n",
    "      {context}\n",
    "    </context>\n",
    "\n",
    "     \"\"\"       \n",
    ")\n",
    "document_chain = create_stuff_documents_chain(llm=llm, prompt=prompt_template)\n",
    "document_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9e0b239b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure, here's the answer to the question:\\n\\nThe LangSmith frontend service must be exposed to users. It is the only component that must be exposed to users.\""
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document \n",
    "document_chain.invoke(\n",
    "    {\n",
    "        \"input_documents\": result_docs, \n",
    "        \"context\": [Document(page_content = \"To access the LangSmith UI and send API requests, you will need to expose the LangSmith frontend service. \" \\\n",
    "        \"Depending on your installation method, this can be a load balancer or a port exposed on the host machine.\" \\\n",
    "        \"You can run LangSmith in Kubernetes (recommended) or Docker in a cloud environment that you control.\" \\\n",
    "        \"The frontend uses Nginx to serve the LangSmith UI and route API requests to the other servers. \" \\\n",
    "        \"This serves as the entrypoint for the application and is the only component that must be exposed to users.\" \\\n",
    "        \"LangSmith uses PostgreSQL as the primary data store for transactional workloads and operational data \"\\\n",
    "        \"(almost everything besides traces and feedback).\" \\\n",
    "        \"Redis is a powerful in-memory key-value database that persists on disk. By holding data in memory, \" \\\n",
    "        \"Redis offers high performance for operations like caching.\" \\\n",
    "        \"LangSmith uses Redis to back queuing and caching operations.\" \\\n",
    "        \"Blob storage LangSmith supports several blob storage providers, including AWS S3, Azure Blob Storage, and Google Cloud Storage.\" \\\n",
    "        \"LangSmith uses blob storage to store large files, such as trace artifacts, feedback attachments, and other large data objects. \" \\\n",
    "        \"Blob storage is optional, but highly recommended for production deployments.\" \\\n",
    "        \"Services LangSmith frontend. The frontend uses Nginx to serve the LangSmith UI and route API requests to the other servers. \" \\\n",
    "        \"This serves as the entrypoint for the application and is the only component that must be exposed to users.LangSmith backend\")],\n",
    "        \"question\": query\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e064cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want the document to come from the retriever we just set up to dynamically \n",
    "# select the most relevant documents and pass those in for a given question\n",
    "## pass input to retriever --> retriever act as an interface --> get output from vectorstoredb\n",
    "\n",
    "retriever = vectorstoredb.as_retriever(search_kwargs={\"k\": 6})\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain) #document_chain provides context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b7a58ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000022D7A6DB460>, search_kwargs={'k': 6}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\n    Answer the following question based only on the provided context:\\n    <context>\\n      {context}\\n    </context>\\n\\n     '), additional_kwargs={})])\n",
       "            | ChatOllama(model='gemma:2b')\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cb3a21fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context does not provide information about the storage services available for LangSmith, so I cannot answer this question from the provided context.'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the response from the llm\n",
    "response = retrieval_chain.invoke(\n",
    "    {\n",
    "        \"input\": query\n",
    "    }\n",
    ")\n",
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a4eaa9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Will need to expose the LangSmith frontend service?',\n",
       " 'context': [Document(id='08dd7d56-6ad5-49ba-90c7-7c2fb618b817', metadata={'source': 'https://docs.langchain.com/langsmith/architectural-overview', 'title': 'Architectural overview - Docs by LangChain', 'language': 'en'}, page_content='\\u200bLangSmith backend\\nThe backend is the main entrypoint for CRUD API requests and handles the majority of the business logic for the application. This includes handling requests from the frontend and SDK, preparing traces for ingestion, and supporting the hub API.\\n\\u200bLangSmith queue\\nThe queue handles incoming traces and feedback to ensure that they are ingested and persisted into the traces and feedback datastore asynchronously, handling checks for data integrity and ensuring successful insert into the datastore, handling retries in situations such as database errors or the temporary inability to connect to the database.\\n\\u200bLangSmith platform backend\\nThe platform backend is another critical service that primarily handles authentication, run ingestion, and other high-volume tasks.\\n\\u200bLangSmith Playground\\nThe playground is a service that handles forwarding requests to various LLM APIs to support the LangSmith Playground feature. This can also be used to connect to your own custom model servers.'),\n",
       "  Document(id='15927d43-64bf-439e-9504-8773d7c79b10', metadata={'source': 'https://docs.langchain.com/langsmith/architectural-overview', 'title': 'Architectural overview - Docs by LangChain', 'language': 'en'}, page_content='You can run LangSmith in Kubernetes (recommended) or Docker in a cloud environment that you control. The LangSmith application consists of several components including LangSmith servers and stateful services:'),\n",
       "  Document(id='28582790-ecf8-4ed1-9f4f-f613b0991d4a', metadata={'source': 'https://docs.langchain.com/langsmith/architectural-overview', 'title': 'Architectural overview - Docs by LangChain', 'language': 'en'}, page_content='backendLangSmith queueLangSmith platform backendLangSmith PlaygroundLangSmith ACE (Arbitrary Code Execution) backendArchitectural overviewCopy pageCopy pageSelf-hosted LangSmith is an add-on to the Enterprise Plan designed for our largest, most security-conscious customers. See our pricing page for more detail, and contact our sales team if you want to get a license key to trial LangSmith in your environment.'),\n",
       "  Document(id='536d08c4-383d-48e5-8803-d838505f212c', metadata={'source': 'https://docs.langchain.com/langsmith/architectural-overview', 'title': 'Architectural overview - Docs by LangChain', 'language': 'en'}, page_content='to an external ClickHouse databaseConnect to an external PostgreSQL databaseConnect to an external Redis databaseScriptsDelete workspacesDelete organizationsDelete tracesGenerate ClickHouse StatsGenerate query statsRun support queries against PostgreSQLRun support queries against ClickHouseObservabilityExport LangSmith telemetry to your observability backendConfigure your collector for telemetryDeploy an observability stackDocs by LangChain home pagePythonSearch...⌘KGitHubForumForumSearch...NavigationArchitectural overviewGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGitHubForumOn this pageStorage ServicesClickHousePostgreSQLRedisBlob storageServicesLangSmith frontendLangSmith backendLangSmith queueLangSmith platform backendLangSmith PlaygroundLangSmith ACE (Arbitrary Code Execution) backendArchitectural overviewCopy pageCopy pageSelf-hosted LangSmith is an add-on to the')],\n",
       " 'answer': 'What is the main entrypoint for CRUD API requests?\\nThe context does not specify the main entrypoint for CRUD API requests, so I cannot answer this question from the provided context.'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52afcab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_community.chat_models import Ollama\n",
    "#from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "#from langchain_core.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
