{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e39007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## aloading all the environment variable\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "# os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"TAVILY_API_KEY\"]=os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ec2424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#hugging face embeddings technique\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "os.environ[\"HUGGING_FACE_API_KEY\"] = os.getenv(\"HUGGING_FACE_API_KEY\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "905c32c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build Index\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "### from langchain_cohere import CohereEmbeddings\n",
    "\n",
    "# Set embeddings\n",
    "embd = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\") # OpenAIEmbeddings()\n",
    "\n",
    "# Docs to index\n",
    "urls = [\n",
    "    \"https://docs.langchain.com/oss/python/langgraph/overview/\",\n",
    "    \"https://docs.langchain.com/oss/python/langgraph/workflows-agents/\",\n",
    "    \"https://docs.langchain.com/oss/python/langgraph/graph-api/\",\n",
    "    \"https://docs.langchain.com/oss/python/langgraph/functional-api/\"\n",
    "]\n",
    "\n",
    "# Load\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorstore\n",
    "vectorstore=FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=embd\n",
    ")\n",
    "\n",
    "\n",
    "retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24f0d63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "# LLM with function call\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\")  #ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "##chain the prompt with the LLM\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "question = \"agent memory\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "428febfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph provides a central benefit of Comprehensive memory, which creates stateful agents with both short-term working memory for ongoing reasoning and long-term memory across sessions. This allows agents to persist through failures and can run for extended periods, resuming from where they left off. This memory enables agents to retain information and learn from previous interactions.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\") #ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32fa8be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here\\'s a re-written version of the question that\\'s optimized for web search:\\n\\n\"What is agent memory, and how does it work in [specific context or application]?\"\\n\\nThis re-written question:\\n\\n1. Adds more specific keywords (\"agent memory\") to make it more search-engine friendly.\\n2. Includes a question about the underlying mechanism (\"how does it work\") to make it more specific and answerable.\\n3. Adds a specific context or application to help narrow down the search results and make them more relevant.\\n\\nExample input with specific context or application: \\n\"What is agent memory in artificial intelligence, and how does it work in cognitive systems?\"\\n\\nThis revised question is more likely to yield accurate and relevant search results.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question Re-writer\n",
    "\n",
    "# LLM\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\") #ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for web search. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0d139ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akirt\\AppData\\Local\\Temp\\ipykernel_19544\\730760015.py:5: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  web_search_tool = TavilySearchResults(k=3)\n"
     ]
    }
   ],
   "source": [
    "### Search\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7674c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        web_search: whether to add search\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search: str\n",
    "    documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb006184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\"\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the re-phrased question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Web search\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    documents.append(web_results)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "073d3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generate\n",
    "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
    "workflow.add_node(\"web_search_node\", web_search)  # web search\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"web_search_node\")\n",
    "workflow.add_edge(\"web_search_node\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a536510e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db9e4904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n"
     ]
    },
    {
     "ename": "APIConnectionError",
     "evalue": "Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\httpx\\_transports\\default.py:101\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\httpcore\\_sync\\connection.py:78\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     ssl_object \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mget_extra_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\httpcore\\_sync\\connection.py:124\u001b[0m, in \u001b[0;36mHTTPConnection._connect\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnect_tcp\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m--> 124\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_backend\u001b[38;5;241m.\u001b[39mconnect_tcp(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    125\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m stream\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\httpcore\\_backends\\sync.py:207\u001b[0m, in \u001b[0;36mSyncBackend.connect_tcp\u001b[1;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[0;32m    202\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    203\u001b[0m     socket\u001b[38;5;241m.\u001b[39mtimeout: ConnectTimeout,\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[0;32m    205\u001b[0m }\n\u001b[1;32m--> 207\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    208\u001b[0m     sock \u001b[38;5;241m=\u001b[39m socket\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    209\u001b[0m         address,\n\u001b[0;32m    210\u001b[0m         timeout,\n\u001b[0;32m    211\u001b[0m         source_address\u001b[38;5;241m=\u001b[39msource_address,\n\u001b[0;32m    212\u001b[0m     )\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\httpcore\\_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[1;34m(map)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[1;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mConnectError\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\groq\\_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 980\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    981\u001b[0m         request,\n\u001b[0;32m    982\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    983\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    984\u001b[0m     )\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\httpx\\_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\httpx\\_transports\\default.py:249\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    248\u001b[0m )\n\u001b[1;32m--> 249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m    250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\httpx\\_transports\\default.py:118\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m    117\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mConnectError\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat are the types of agent memory?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langgraph\\pregel\\main.py:3068\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[0;32m   3065\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   3066\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 3068\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   3069\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3070\u001b[0m     config,\n\u001b[0;32m   3071\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m   3072\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   3073\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[0;32m   3075\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[0;32m   3076\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   3077\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   3078\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   3079\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[0;32m   3080\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3081\u001b[0m ):\n\u001b[0;32m   3082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   3083\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langgraph\\pregel\\main.py:2657\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2655\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2656\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2657\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2658\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2659\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2660\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2661\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2662\u001b[0m ):\n\u001b[0;32m   2663\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2664\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[0;32m   2665\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[0;32m   2666\u001b[0m     )\n\u001b[0;32m   2667\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    160\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 657\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[11], line 60\u001b[0m, in \u001b[0;36mgrade_documents\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     58\u001b[0m web_search \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[1;32m---> 60\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mretrieval_grader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocument\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     grade \u001b[38;5;241m=\u001b[39m score\u001b[38;5;241m.\u001b[39mbinary_score\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m grade \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:3246\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3244\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3245\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3246\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3247\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3248\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:5711\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5704\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   5705\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5706\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5709\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5710\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5711\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5712\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5713\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5714\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5715\u001b[0m     )\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:395\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    391\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    392\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 395\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    396\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    397\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    398\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    399\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    400\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    401\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    402\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    403\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    404\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    405\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1025\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1023\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m   1024\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m-> 1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:842\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    841\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 842\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    843\u001b[0m                 m,\n\u001b[0;32m    844\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    845\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    846\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    847\u001b[0m             )\n\u001b[0;32m    848\u001b[0m         )\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    850\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1091\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1089\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1091\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1092\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1093\u001b[0m     )\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1095\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langchain_groq\\chat_models.py:533\u001b[0m, in \u001b[0;36mChatGroq._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    529\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    532\u001b[0m }\n\u001b[1;32m--> 533\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(messages\u001b[38;5;241m=\u001b[39mmessage_dicts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, params)\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\groq\\resources\\chat\\completions.py:448\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, compound_custom, documents, exclude_domains, frequency_penalty, function_call, functions, include_domains, include_reasoning, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    295\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    296\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    297\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompound_custom\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompound_custom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocuments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexclude_domains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude_domains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude_reasoning\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_reasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msearch_settings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\groq\\_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1241\u001b[0m     )\n\u001b[1;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\groq\\_base_client.py:1012\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1009\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1012\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1016\u001b[0m     request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     response\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1021\u001b[0m )\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mAPIConnectionError\u001b[0m: Connection error."
     ]
    }
   ],
   "source": [
    "app.invoke({\"question\":\"What are the types of agent memory?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5075eccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
