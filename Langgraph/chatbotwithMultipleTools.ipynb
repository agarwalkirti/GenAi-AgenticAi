{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13d3bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building chatbot with multiple tools- arxiv,wikipedia search,tavily search and custom functions like add,multiply using Langgraph\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# open source model from groq\n",
    "from langchain_groq import ChatGroq\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "# LLM with function call\n",
    "llm=ChatGroq(groq_api_key=api_key,model_name=\"llama-3.1-8b-instant\")\n",
    "os.environ[\"TAVILY_API_KEY\"]=os.getenv(\"TAVILY_API_KEY\")\n",
    "# Set environment variables for LangSmith tracking and LangChain project\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGRAPH_LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27fd62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Annotated # we can see all messages in conversation in form of list\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages # reducer to add messages to state\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from pprint import pprint # pretty print\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bad684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper,WikipediaAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "## Working With Tools\n",
    "## Arxiv And Wikipedia tools\n",
    "arxiv_wrapper=ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=300)\n",
    "arxiv_tool=ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "\n",
    "api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=300)\n",
    "wiki_tool=WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "#wiki_tool.invoke(\"who is Sharukh Khan\")\n",
    "#arxiv_tool.invoke(\"Attention is all you need\")\n",
    "\n",
    "## tavily search tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily_tool =TavilySearchResults()\n",
    "#tavily_tool.invoke(\"Provide me recent AI news for 16th october 2025\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8bc7675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool use with function calling and docstrings\n",
    "# custom functions\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\" \n",
    "    Add a and b \n",
    "    Args: \n",
    "        a: first integer\n",
    "        b: second integer \n",
    "    returns:\n",
    "        integer result\n",
    "    \"\"\"\n",
    "    result = a + b\n",
    "    return result\n",
    "\n",
    "\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\" \n",
    "    Multiply a and b \n",
    "    Args: \n",
    "        a: first float\n",
    "        b: second float \n",
    "    returns:\n",
    "        float result\n",
    "    \"\"\"\n",
    "    result = a * b\n",
    "    return result\n",
    "\n",
    "def Divide(a: float, b: float) -> float:\n",
    "    \"\"\" \n",
    "    Divide a and b \n",
    "    Args: \n",
    "        a: first float\n",
    "        b: non zero second float \n",
    "    returns:\n",
    "        float result\n",
    "    \"\"\"\n",
    "    result = a / b\n",
    "    return result\n",
    "\n",
    "def tavily_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the Tavily knowledge base for relevant information.\n",
    "    Args:\n",
    "        query: The search query string.\n",
    "    Returns:\n",
    "        A string containing the search results.\n",
    "    \"\"\"\n",
    "    results = tavily_tool.invoke(query)\n",
    "    return f\"Tavily search results for '{query}': {results}\"\n",
    "\n",
    "def arxiv_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the Arxiv knowledge base for relevant research paper information.\n",
    "    Args:\n",
    "        query: The search query string.\n",
    "    Returns:\n",
    "        A string containing the search results.\n",
    "    \"\"\"\n",
    "    results = arxiv_tool.invoke(query)\n",
    "    return f\"Arxiv search results for '{query}': {results}\"\n",
    "\n",
    "def wiki_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the Wikipedia knowledge base for relevant wikipedia information.\n",
    "    Args:\n",
    "        query: The search query string.\n",
    "    Returns:\n",
    "        A string containing the search results.\n",
    "    \"\"\"\n",
    "    results = wiki_tool.invoke(query)\n",
    "    return f\"Wikipedia search results for '{query}': {results}\"\n",
    "\n",
    "# we can add rag custom tool too and anyother tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6faea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import StructuredTool\n",
    "\n",
    "# wrap each of your custom functions\n",
    "add_tool = StructuredTool.from_function(add)\n",
    "multiply_tool = StructuredTool.from_function(multiply)\n",
    "divide_tool = StructuredTool.from_function(Divide)\n",
    "tavily_tool_wrapped = StructuredTool.from_function(tavily_search)\n",
    "arxiv_tool_wrapped = StructuredTool.from_function(arxiv_search)\n",
    "wiki_tool_wrapped = StructuredTool.from_function(wiki_search)\n",
    "\n",
    "tools = [add_tool, multiply_tool, divide_tool, tavily_tool_wrapped, arxiv_tool_wrapped, wiki_tool_wrapped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f958780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'arxiv_search',\n",
       "  'args': {'query': 'AI news 16th October 2025'},\n",
       "  'id': '59hm3ajqa',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'tavily_search',\n",
       "  'args': {'query': 'AI news 16th October 2025'},\n",
       "  'id': '4h2m7761s',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'wiki_search',\n",
       "  'args': {'query': 'AI news 16th October 2025'},\n",
       "  'id': 'z48ab5m6y',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tools=[wiki_search,arxiv_search,add,multiply,tavily_search]\n",
    "\n",
    "# binding tool with llm\n",
    "llm_with_tools=llm.bind_tools(tools=tools)\n",
    "llm_with_tools.invoke([HumanMessage(content=\"What is recent AI news as on 16th october 2025?\")]).tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "731040ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define state schema\n",
    "class State(BaseModel):\n",
    "    messages:Annotated[list[AnyMessage],add_messages]\n",
    "    #list of AI and Human messages, this will be the information flowing in graph, to avoid overwriting of messages we will use reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a184006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node definition\n",
    "\n",
    "def tool_calling_llm(state:State):\n",
    "    return {\"messages\": state.messages + [llm_with_tools.invoke(state.messages)] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47eec2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building graph\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# nodes\n",
    "graph_builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# if the latest message (result) from assistant is a tool call, then tools_condition route to mentioned tool node\n",
    "# if the latest message (result) from assistant is not a tool call,then tools_condition route to end node\n",
    "# edges\n",
    "graph_builder.add_edge(START, \"tool_calling_llm\")\n",
    "graph_builder.add_conditional_edges(\"tool_calling_llm\", tools_condition,\n",
    "                                    {\n",
    "                                        \"tools\": \"tools\",\n",
    "                                        \"__end__\": END,  # If no tool call, go to END\n",
    "                                    },\n",
    "    )\n",
    "\n",
    "graph_builder.add_edge(\"tools\", \"tool_calling_llm\")\n",
    "graph_builder.add_edge(\"tool_calling_llm\",END)\n",
    "\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f72f9743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "## visualize graph as mermaid diagram\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90d031dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is machine learning?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  wiki_search (dfeh1dry8)\n",
      " Call ID: dfeh1dry8\n",
      "  Args:\n",
      "    query: machine learning definition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: wiki_search\n",
      "\n",
      "Wikipedia search results for 'machine learning definition': Page: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions. Within a subdiscipline\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  wiki_search (55aevq2pp)\n",
      " Call ID: 55aevq2pp\n",
      "  Args:\n",
      "    query: machine learning subdisciplines\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: wiki_search\n",
      "\n",
      "Error: ConnectTimeout(MaxRetryError(\"HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=machine+learning+subdisciplines&format=json&action=query (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x00000251766F0040>, 'Connection to en.wikipedia.org timed out. (connect timeout=None)'))\"))\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  arxiv_search (ysfg2d6yh)\n",
      " Call ID: ysfg2d6yh\n",
      "  Args:\n",
      "    query: machine learning subdisciplines\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: arxiv_search\n",
      "\n",
      "Arxiv search results for 'machine learning subdisciplines': Published: 2021-10-06\n",
      "Title: Interpretable Machine Learning for Genomics\n",
      "Authors: David S. Watson\n",
      "Summary: High-throughput technologies such as next generation sequencing allow\n",
      "biologists to observe cell function with unprecedented resolution, but the\n",
      "resulting datasets are too large and complicated\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (h9gd7n3m9)\n",
      " Call ID: h9gd7n3m9\n",
      "  Args:\n",
      "    query: machine learning subdisciplines\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "Tavily search results for 'machine learning subdisciplines': [{'title': 'Machine learning - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/Machine_learning', 'content': 'Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks \"Task (computing)\") without explicit instructions. Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks \"Neural network (machine learning)\"), a class of statistical algorithms, to surpass many previous machine learning [...] | Problems   Classification  Generative modeling  Regression  Clustering  Dimensionality reduction  Density estimation  Anomaly detection  Data cleaning  AutoML  Association rules  Semantic analysis \"Semantic analysis (machine learning)\")  Structured prediction  Feature engineering  Feature learning  Learning to rank  Grammar induction  Ontology learning  Multimodal learning | [...] | Part of a series on |\\n| Artificial intelligence (AI) |\\n| Major goals   Artificial general intelligence  Intelligent agent  Recursive self-improvement  Planning  Computer vision  General game playing  Knowledge representation  Natural language processing  Robotics  AI safety |\\n| Approaches   Machine learning  Symbolic  Deep learning  Bayesian networks  Evolutionary algorithms  Hybrid intelligent systems  Systems integration  Open-source |', 'score': 0.71040785}, {'title': 'Outline of machine learning - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/Outline_of_machine_learning', 'content': '## How can machine learning be categorized?\\n\\n[edit]\\n\\n An academic discipline\\n A branch of science\\n  + An applied science\\n    - A subfield of computer science\\n       A branch of artificial intelligence\\n       A subfield of soft computing\\n       Application of statistics\\n\\n### Paradigms of machine learning\\n\\n[edit] [...] | General |  Differentiable programming  Information geometry  Statistical manifold  Automatic differentiation  Neuromorphic computing  Pattern recognition  Ricci calculus  Computational learning theory  Inductive bias |\\n| Hardware |  IPU  TPU  VPU  Memristor  SpiNNaker |\\n| Software libraries |  TensorFlow  PyTorch  Keras  scikit-learn  Theano \"Theano (software)\")  JAX \"JAX (software)\")  Flux.jl \"Flux (machine-learning framework)\")  MindSpore | [...] Multiple instance learning\\n Multiple-instance learning\\n Never-Ending Language Learning\\n Offline learning\\n Parity learning\\n Population-based incremental learning\\n Predictive learning\\n Preference learning\\n Proactive learning\\n Proximal gradient methods for learning\\n Semantic analysis \"Semantic analysis (machine learning)\")\\n Similarity learning\\n Sparse dictionary learning\\n Stability (learning theory) \"Stability (learning theory)\")\\n Statistical learning theory\\n Statistical relational learning', 'score': 0.64719695}, {'title': 'Types of Machine Learning - GeeksforGeeks', 'url': 'https://www.geeksforgeeks.org/machine-learning/types-of-machine-learning/', 'content': 'Image classification: Identify objects, faces, and other features in images.\\n Natural language processing: Extract information from text, such as sentiment, entities, and relationships.\\n Speech recognition: Convert spoken language into text.\\n Recommendation systems: Make personalized recommendations to users.\\n Predictive analytics: Predict outcomes, such as sales, customer churn, and stock prices.\\n Medical diagnosis: Detect diseases and other medical conditions. [...] Clustering: Group similar data points into clusters.\\n Anomaly detection: Identify outliers or anomalies in data.\\n Dimensionality reduction: Reduce the dimensionality of data while preserving its essential information.\\n Recommendation systems: Suggest products, movies, or content to users based on their historical behavior or preferences.\\n Topic modeling: Discover latent topics within a collection of documents.\\n Density estimation: Estimate the probability density function of data. [...] Image Classification and Object Recognition: Improve the accuracy of models by combining a small set of labeled images with a larger set of unlabeled images.\\n Natural Language Processing (NLP): Enhance the performance of language models and classifiers by combining a small set of labeled text data with a vast amount of unlabeled text.', 'score': 0.54594}, {'title': 'Machine learning, explained | MIT Sloan', 'url': 'https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained', 'content': '“The function of a machine learning system can be descriptive, meaning that the system uses the data to explain what happened; predictive, meaning the system uses the data to predict what will happen; or prescriptive, meaning the system will use the data to make suggestions about what action to take,” the researchers wrote.\\n\\nThere are three subcategories of machine learning: [...] What is machine learning?\\n\\nMachine learning is a subfield of artificial intelligence, which is broadly defined as the capability of a machine to imitate intelligent human behavior. Artificial intelligence systems are used to perform complex tasks in a way that is similar to how humans solve problems.', 'score': 0.51076555}, {'title': 'Types of Machine Learning | IBM', 'url': 'https://www.ibm.com/think/topics/machine-learning-types', 'content': 'ML is a computer science, data science and artificial intelligence (AI) subset that enables systems to learn and improve from data without additional programming interventions.\\n\\nInstead of using explicit instructions for performance optimization, ML models rely on algorithms and statistical models that deploy tasks based on data patterns and inferences. In other words, ML leverages input data to predict outputs, continuously updating outputs as new data becomes available. [...] Mixture of Experts | 10 October, episode 76\\n\\n### Decoding AI: Weekly News Roundup\\n\\nJoin our world-class panel of engineers, researchers, product leaders and more as they cut through the AI noise to bring you the latest in AI news and insights.\\n\\nWatch all episodes of Mixture of Experts\\n\\n## Machine learning types\\n\\nMachine learning algorithms fall into five broad categories: supervised learning, unsupervised learning, semi-supervised learning, self-supervised and reinforcement learning. [...] Neural networks—simulate the way the human brain works, with a huge number of linked processing nodes that can facilitate processes like natural language translation, image recognition, speech recognition and image creation.\\n Random forest algorithms—predict a value or category by combining the results from a number of decision trees.', 'score': 0.49494705}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The subdisciplines of machine learning include:\n",
      "\n",
      "* Supervised learning\n",
      "* Unsupervised learning\n",
      "* Semi-supervised learning\n",
      "* Self-supervised learning\n",
      "* Reinforcement learning\n",
      "\n",
      "Additionally, machine learning can be categorized into different paradigms, such as:\n",
      "\n",
      "* General\n",
      "* Hardware\n",
      "* Software libraries\n",
      "\n",
      "Machine learning can also be used for various tasks, including:\n",
      "\n",
      "* Image classification\n",
      "* Natural language processing\n",
      "* Speech recognition\n",
      "* Recommendation systems\n",
      "* Predictive analytics\n",
      "* Medical diagnosis\n",
      "\n",
      "It can also be used for clustering, anomaly detection, dimensionality reduction, and density estimation.\n",
      "\n",
      "There are also different types of machine learning, such as:\n",
      "\n",
      "* Mixture of Experts\n",
      "* Neural networks\n",
      "* Random forest algorithms\n",
      "\n",
      "Machine learning can be used for various applications, including:\n",
      "\n",
      "* Image classification and object recognition\n",
      "* Natural language processing\n",
      "* Recommendation systems\n",
      "* Topic modeling\n",
      "* Density estimation\n",
      "\n",
      "Machine learning can be categorized into different types, such as:\n",
      "\n",
      "* Descriptive\n",
      "* Predictive\n",
      "* Prescriptive\n",
      "\n",
      "Machine learning is a subfield of artificial intelligence, which is broadly defined as the capability of a machine to imitate intelligent human behavior.\n"
     ]
    }
   ],
   "source": [
    "graph_result = graph.invoke({\"messages\":HumanMessage(content= \"What is machine learning?\")}) \n",
    "\n",
    "for message in graph_result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16bff54e",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"tool call validation failed: attempted to call tool 'wikipedia_search' which was not in request.tools\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=wikipedia_search>{\"query\": \"Jakob Uszkoreit\"}</function>'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m graph_result \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1706.03762?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m graph_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      4\u001b[0m     message\u001b[38;5;241m.\u001b[39mpretty_print()\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langgraph\\pregel\\main.py:3068\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[0;32m   3065\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   3066\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 3068\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   3069\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3070\u001b[0m     config,\n\u001b[0;32m   3071\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m   3072\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   3073\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[0;32m   3075\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[0;32m   3076\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   3077\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   3078\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   3079\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[0;32m   3080\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3081\u001b[0m ):\n\u001b[0;32m   3082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   3083\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langgraph\\pregel\\main.py:2657\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2655\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2656\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2657\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2658\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2659\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2660\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2661\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2662\u001b[0m ):\n\u001b[0;32m   2663\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2664\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[0;32m   2665\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[0;32m   2666\u001b[0m     )\n\u001b[0;32m   2667\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    160\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 657\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[34], line 4\u001b[0m, in \u001b[0;36mtool_calling_llm\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtool_calling_llm\u001b[39m(state:State):\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: state\u001b[38;5;241m.\u001b[39mmessages \u001b[38;5;241m+\u001b[39m [\u001b[43mllm_with_tools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m] }\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:5711\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5704\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   5705\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5706\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5709\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5710\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5711\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5712\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5713\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5714\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5715\u001b[0m     )\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:395\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    391\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    392\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 395\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    396\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    397\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    398\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    399\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    400\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    401\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    402\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    403\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    404\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    405\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1025\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1023\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m   1024\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m-> 1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:842\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    841\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 842\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    843\u001b[0m                 m,\n\u001b[0;32m    844\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    845\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    846\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    847\u001b[0m             )\n\u001b[0;32m    848\u001b[0m         )\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    850\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1091\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1089\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1091\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1092\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1093\u001b[0m     )\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1095\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\langchain_groq\\chat_models.py:533\u001b[0m, in \u001b[0;36mChatGroq._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    529\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    532\u001b[0m }\n\u001b[1;32m--> 533\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(messages\u001b[38;5;241m=\u001b[39mmessage_dicts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, params)\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\groq\\resources\\chat\\completions.py:448\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, compound_custom, documents, exclude_domains, frequency_penalty, function_call, functions, include_domains, include_reasoning, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    295\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    296\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    297\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompound_custom\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompound_custom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocuments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexclude_domains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude_domains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude_reasoning\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_reasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msearch_settings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\groq\\_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1241\u001b[0m     )\n\u001b[1;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\study\\udemy\\langchain\\venv\\lib\\site-packages\\groq\\_base_client.py:1044\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1043\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1044\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"tool call validation failed: attempted to call tool 'wikipedia_search' which was not in request.tools\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=wikipedia_search>{\"query\": \"Jakob Uszkoreit\"}</function>'}}"
     ]
    }
   ],
   "source": [
    "graph_result = graph.invoke({\"messages\":HumanMessage(content= \"1706.03762?\")}) \n",
    "\n",
    "for message in graph_result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62489d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Provide me to 3 recent AI news as on today\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  arxiv_search (0ctwjzcpm)\n",
      " Call ID: 0ctwjzcpm\n",
      "  Args:\n",
      "    query: Recent advances in AI\n",
      "  wiki_search (x4e9tctne)\n",
      " Call ID: x4e9tctne\n",
      "  Args:\n",
      "    query: Recent AI news\n",
      "  tavily_search (c028yjttx)\n",
      " Call ID: c028yjttx\n",
      "  Args:\n",
      "    query: Recent AI news updates\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: arxiv_search\n",
      "\n",
      "Arxiv search results for 'Recent advances in AI': Published: 2025-01-15\n",
      "Title: Trustworthy, Responsible, and Safe AI: A Comprehensive Architectural Framework for AI Safety with Challenges and Mitigations\n",
      "Authors: Chen Chen, Xueluan Gong, Ziyao Liu, Weifeng Jiang, Si Qi Goh, Kwok-Yan Lam\n",
      "Summary: AI Safety is an emerging area of critical importance \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: wiki_search\n",
      "\n",
      "Wikipedia search results for 'Recent AI news': Page: Generative AI pornography\n",
      "Summary: Generative AI pornography or simply AI pornography is a digitally created pornography produced through generative artificial intelligence (AI) technologies. Unlike traditional pornography, which involves real actors and cameras, this content is synthesized en\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "Tavily search results for 'Recent AI news updates': [{'title': 'Daily Digest on AI and Emerging Technologies (13 October 2025)', 'url': 'https://www.cgspam.org/daily-digest-on-ai-and-emerging-technologies-13-october-2025/', 'content': '(DigWatch – 10 October 2025) Countries are racing to harness AI, and the European Commission has unveiled two strategies to maintain Europe’s competitiveness. Apply AI targets faster adoption across industries and the public sector, while AI in Science focuses on boosting Europe’s research leadership. Commission President Ursula von der Leyen stated that Europe must shape AI’s future by balancing innovation and safety. The European Commission is mobilising €1 billion to boost adoption in [...] (DigWatch – 10 October 2025) The OSCE has launched a new publication warning that rapid progress in AI threatens the fundamental human right to freedom of thought. The report, Think Again: Freedom of Thought in the Age of AI, calls on governments to create human rights-based safeguards for emerging technologies. –  – \\n\\nRetailers face new pressure under California privacy law [...] (AI Insider – 10 October 2025) DoorDash and Serve Robotics announced a multi-year partnership to deploy autonomous sidewalk deliveries across the U.S., starting with select Los Angeles merchants on the DoorDash app. The deal advances DoorDash’s multi-modal logistics strategy—integrating Dashers, drones, and robots via its Autonomous Delivery Platform—to match orders to the most effective, lower-emission method. Serve brings 100,000+ completed autonomous deliveries from 2,500+ restaurants in', 'score': 0.78572035}, {'title': 'The 2025 AI Index Report | Stanford HAI', 'url': 'https://hai.stanford.edu/ai-index/2025-ai-index-report', 'content': '### 2. AI is increasingly embedded in everyday life.\\n\\nFrom healthcare to transportation, AI is rapidly moving from the lab to daily life. In 2023, the FDA approved 223 AI-enabled medical devices, up from just six in 2015. On the roads, self-driving cars are no longer experimental: Waymo, one of the largest U.S. operators, provides over 150,000 autonomous rides each week, while Baidu’s affordable Apollo Go robotaxi fleet now serves numerous cities across China. [...] In 2024, U.S. federal agencies introduced 59 AI-related regulations—more than double the number in 2023—and issued by twice as many agencies. Globally, legislative mentions of AI rose 21.3% across 75 countries since 2023, marking a ninefold increase since 2016. Alongside growing attention, governments are investing at scale: Canada pledged $2.4 billion, China launched a $47.5 billion semiconductor fund, France committed €109 billion, India pledged $1.25 billion, and Saudi Arabia’s Project [...] In 2024, U.S. private AI investment grew to $109.1 billion—nearly 12 times China’s $9.3 billion and 24 times the U.K.’s $4.5 billion. Generative AI saw particularly strong momentum, attracting $33.9 billion globally in private investment—an 18.7% increase from 2023. AI business usage is also accelerating: 78% of organizations reported using AI in 2024, up from 55% the year before. Meanwhile, a growing body of research confirms that AI boosts productivity and, in most cases, helps narrow skill', 'score': 0.6824261}, {'title': 'AI News & Artificial Intelligence | TechCrunch', 'url': 'https://techcrunch.com/category/artificial-intelligence/', 'content': \"large Reddit logo overlaying background of smaller logo silhouettes\\n\\n### Reddit expands its AI-powered search to 5 new languages\\n\\n### OpenAI pauses Sora video generations of Martin Luther King Jr.\\n\\n### Kayak launches an ‘AI Mode’ for travel questions, search, and bookings\\n\\nDigital generated image of abstract cloud / data visualization on purple background.\\n\\n### Why AI startups are taking data into their own hands [...] Mark Zuckerberg, chief executive officer of Meta Platforms Inc., during the Meta Connect event in Menlo Park, California, US, on Wednesday, Sept. 25, 2024. Meta Platforms Inc. debuted its first pair of augmented reality glasses, devices that show a combined view of the digital and physical worlds, a key step in Chief Executive Officer Mark Zuckerberg's goal of one day offering a hands-free alternative to the smartphone. Photographer: David Paul Morris/Bloomberg via Getty Images [...] ### Eightfold co-founders raise $35M for Viven, an AI digital twin startup for querying unavailable co-workers\\n\\nLiberate founders\\n\\n### Liberate bags $50M at $300M valuation to bring AI deeper into insurance back offices\\n\\nA screenshot of Claude Code in action, with a window of code facing a web page\\n\\n### Anthropic launches new version of scaled-down ‘Haiku’ model\", 'score': 0.6755297}, {'title': 'The AI Boom of October 2025: What You Missed in the Fastest ...', 'url': 'https://medium.com/@simohamed.amara/the-ai-boom-of-october-2025-what-you-missed-in-the-fastest-month-of-innovation-ad9466d3159b', 'content': 'OpenAI unveiled Sora 2, its next-gen video model that merges audio, motion, and likeness generation.  \\nThat means you can now generate realistic video scenes with sync’d voices and recognizable faces, giving creators tools once reserved for movie studios.\\n\\n🟢 New feature: “Cameos” — upload your voice or short video, and Sora can place you inside an AI-generated film.\\n\\n--\\n\\n--\\n\\nAmara\\nAmara\\n\\n## Written by Amara [...] October 2025 wasn’t just another month in tech — it was a leap.  \\nFrom OpenAI’s cinematic AI to Google’s computer-controlling Gemini, to humanoid robots that think, this month proved one thing:\\n\\nThe AI revolution isn’t coming. It’s already walking, talking, and coding beside us.\\n\\nLet’s recap the innovations that everyone in tech (and outside it) should know.\\n\\n## 🎬 OpenAI Sora 2: Where AI Meets Cinema [...] Sign up\\n\\nSign in\\n\\nSign up\\n\\nSign in\\n\\nMember-only story\\n\\n# The AI Boom of October 2025: What You Missed in the Fastest Month of Innovation\\n\\n## From multimodal marvels to robot revolutions — here’s a recap of the biggest AI breakthroughs that are shaping the future.\\n\\nAmara\\n\\n--\\n\\nShare\\n\\nWritten by Simohamed Amara\\n\\n## 🚀 The Month AI Grew New Arms, Eyes, and Voices', 'score': 0.6018984}, {'title': 'Why this analyst says the AI bubble is 17 times bigger than the dot ...', 'url': 'https://www.cnn.com/2025/10/18/business/ai-bubble-analyst-nightcap', 'content': 'Just this week, the Financial Times wrote that 10 AI startups — not a dollar in profit among them — have gained nearly $1 trillion in market value over the past 12 months. (That is, to use a technical term, bananas.) [...] Open AI CEO Sam Altman speaks during Snowflake Summit 2025 at Moscone Center on June 2, 2025 in San Francisco, California.\\n\\nYet another OpenAI financial entanglement is renewing fears of a repeat of the dot-com era\\n\\nThere are plenty of skeptics countering the AI hype machine, though few professional market analysts have done so as stridently as Julien Garran, a researcher and partner at the UK firm MacroStrategy Partnership.', 'score': 0.58862966}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the search results, here are three recent AI news articles:\n",
      "\n",
      "1. OpenAI unveiled Sora 2, its next-gen video model that merges audio, motion, and likeness generation, allowing creators to generate realistic video scenes with sync’d voices and recognizable faces.\n",
      "2. Google's computer-controlling Gemini has been announced, a humanoid robot that thinks and can perform tasks independently.\n",
      "3. The AI bubble is 17 times bigger than the dot-com bubble, with 10 AI startups gaining nearly $1 trillion in market value over the past 12 months, according to analyst Julien Garran.\n"
     ]
    }
   ],
   "source": [
    "graph_result = graph.invoke({\"messages\":HumanMessage(content= \"Provide me to 3 recent AI news as on today\")}) \n",
    "\n",
    "for message in graph_result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2706fd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is 2+7?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (8f1c6rwtd)\n",
      " Call ID: 8f1c6rwtd\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 7\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "graph_result = graph.invoke({\"messages\":HumanMessage(content= \"What is 2+7?\")}) \n",
    "\n",
    "for message in graph_result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c1ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is 2 * 7?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (0v7nam0xh)\n",
      " Call ID: 0v7nam0xh\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 7\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "14.0\n"
     ]
    }
   ],
   "source": [
    "graph_result = graph.invoke({\"messages\":HumanMessage(content= \"What is 2 * 7?\")}) \n",
    "\n",
    "for message in graph_result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bd72ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Who is Shahrukh khan?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  wiki_search (p95jrr6e4)\n",
      " Call ID: p95jrr6e4\n",
      "  Args:\n",
      "    query: Shahrukh Khan\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: wiki_search\n",
      "\n",
      "Wikipedia search results for 'Shahrukh Khan': Page: Shah Rukh Khan\n",
      "Summary: Shahrukh Khan (pronounced [ˈʃaːɦɾʊx xäːn] ; born 2 November 1965), and popularly known by the initials SRK, is an Indian actor and film producer renowned for his work in Hindi cinema. Referred to in the media as the \"Baadshah of Bollywood\" and \"King Khan\", he has appear\n"
     ]
    }
   ],
   "source": [
    "graph_result = graph.invoke({\"messages\":HumanMessage(content= \"Who is Shahrukh khan?\")}) \n",
    "\n",
    "for message in graph_result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9518fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "add 5 + 2 and then multiply result of addition by 10\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (trn5t4vkm)\n",
      " Call ID: trn5t4vkm\n",
      "  Args:\n",
      "    a: 5\n",
      "    b: 2\n",
      "  multiply (8ax3xgtfm)\n",
      " Call ID: 8ax3xgtfm\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 10\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "70.0\n"
     ]
    }
   ],
   "source": [
    "graph_result = graph.invoke({\"messages\":HumanMessage(content= \"add 5 + 2 and then multiply result of addition by 10\")}) \n",
    "\n",
    "for message in graph_result['messages']:\n",
    "    message.pretty_print()# react agent architecture query with multiple tools. act,observe and reason. tool output response comes back to llm for final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c84740b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "divide that by 5\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I don't have enough information to perform the operation. What numbers would you like me to divide by 5?\n"
     ]
    }
   ],
   "source": [
    "graph_result = graph.invoke({\"messages\":HumanMessage(content= \"divide that by 5\")}) \n",
    "\n",
    "for message in graph_result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9404b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent memory with multiple tool calls and llm reasoning can be built further\n",
    "# memory saver - checkpointer to automatically save and load graph state from disk or db\n",
    "# thread - collection of checkpoints\n",
    "from langgraph.checkpoint.memory import MemorySaver #, Thread\n",
    "memory = MemorySaver()\n",
    "#thread = Thread(name=\"chatbot_with_multiple_tools_thread\", memory_saver=memory)\n",
    "config = {\"configurable\":{\"thread_id\":\"1\"}}\n",
    "graph_memory = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93d3982a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "add 5 + 2 and then multiply result of addition by 10\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (rgvztxb1e)\n",
      " Call ID: rgvztxb1e\n",
      "  Args:\n",
      "    a: 5\n",
      "    b: 2\n",
      "  multiply (y35dq95we)\n",
      " Call ID: y35dq95we\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 10\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "70.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of the addition is 7 and the result of the multiplication is 70.\n"
     ]
    }
   ],
   "source": [
    "graph_result = graph_memory.invoke({\"messages\":HumanMessage(content= \"add 5 + 2 and then multiply result of addition by 10\")},config=config) \n",
    "\n",
    "for message in graph_result['messages']:\n",
    "    message.pretty_print()# react agent architecture query with multiple tools. act,observe and reason. tool output response comes back to llm for final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf96cf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "add 5 + 2 and then multiply result of addition by 10\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (rgvztxb1e)\n",
      " Call ID: rgvztxb1e\n",
      "  Args:\n",
      "    a: 5\n",
      "    b: 2\n",
      "  multiply (y35dq95we)\n",
      " Call ID: y35dq95we\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 10\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "70.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of the addition is 7 and the result of the multiplication is 70.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "divide that by 5\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Divide (ycgyje8rq)\n",
      " Call ID: ycgyje8rq\n",
      "  Args:\n",
      "    a: 70\n",
      "    b: 5\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: Divide\n",
      "\n",
      "14.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of the division is 14.\n"
     ]
    }
   ],
   "source": [
    "graph_result = graph_memory.invoke({\"messages\":HumanMessage(content= \"divide that by 5\")},config=config) \n",
    "\n",
    "for message in graph_result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4805ff49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fb2f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27cf49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1129fa43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
